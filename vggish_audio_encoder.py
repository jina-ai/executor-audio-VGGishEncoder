__copyright__ = "Copyright (c) 2021 Jina AI Limited. All rights reserved."
__license__ = "Apache-2.0"

import os
from typing import Any, Optional, List, Iterable
import tensorflow as tf
tf.compat.v1.disable_eager_execution()

from jina import Executor, requests, Document, DocumentArray
from vggish.vggish_postprocess import *
from vggish.vggish_slim import *

cur_dir = os.path.dirname(os.path.abspath(__file__))


def _batch_generator(data: List[Any], batch_size: int):
    for i in range(0, len(data), batch_size):
        yield data[i: i + batch_size]


class VggishAudioEncoder(Executor):
    """
     Encode audio data with Vggish embeddings

     :param model_path: path of the pre-trained Vggish model
     :param pca_path: path of the pre-trained PCA model
     :param default_batch_size: fallback traversal path in case there is not traversal path sent in the request
     :param default_traversal_paths: fallback batch size in case there is not batch size sent in the request
     """

    def __init__(self,
                 model_path: str = os.path.join(cur_dir, 'models/vggish_model.ckpt'),
                 pca_path: str = os.path.join(cur_dir, 'models/vggish_pca_params.npz'),
                 default_batch_size: int = 128,
                 default_traversal_paths: Iterable[str] = ['r'],
                 *args, **kwargs):

        super().__init__(*args, **kwargs)
        self.model_path = model_path
        self.pca_path = pca_path
        self.default_batch_size = default_batch_size
        self.default_traversal_paths = default_traversal_paths

        self.sess = tf.compat.v1.Session()
        define_vggish_slim()
        load_vggish_slim_checkpoint(self.sess, self.model_path)
        self.feature_tensor = self.sess.graph.get_tensor_by_name(
            INPUT_TENSOR_NAME)
        self.embedding_tensor = self.sess.graph.get_tensor_by_name(
            OUTPUT_TENSOR_NAME)
        self.post_processor = Postprocessor(self.pca_path)

    def post_init(self):

        self.to_device()
        self.sess = tf.compat.v1.Session()
        define_vggish_slim()
        load_vggish_slim_checkpoint(self.sess, self.model_path)
        self.feature_tensor = self.sess.graph.get_tensor_by_name(
            INPUT_TENSOR_NAME)
        self.embedding_tensor = self.sess.graph.get_tensor_by_name(
            OUTPUT_TENSOR_NAME)
        self.post_processor = Postprocessor(self.pca_path)

    @requests
    def encode(self, docs: Optional[DocumentArray], parameters: dict, *args, **kwargs) -> Any:

        if docs:
            document_batches_generator = self._get_input_data_generator(docs, parameters)
            self._create_embeddings(document_batches_generator)

    def _get_input_data_generator(self, docs: DocumentArray, parameters: dict):
        """Create a batch generator to iterate over text in a document (or document chunks)."""

        traversal_paths = parameters.get('traversal_paths', self.default_traversal_paths)
        batch_size = parameters.get('batch_size', self.default_batch_size)

        # traverse thought all documents which have to be processed
        flat_docs = docs.traverse_flat(traversal_paths)

        # filter out documents without images
        filtered_docs = DocumentArray([doc for doc in flat_docs if doc.blob is not None])

        return _batch_generator(filtered_docs, batch_size)

    def _create_embeddings(self, document_batches_generator: Iterable):
        """Update the documents with the embeddings generated by a tfidf"""

        for document_batch in document_batches_generator:
            batch_features = [d.blob for d in document_batch]
            [embedding] = self.sess.run([self.embedding_tensor],
                                        feed_dict={self.feature_tensor: batch_features})
            result = self.post_processor.postprocess(embedding)
            embedding_matrix = (np.float32(result) - 128.) / 128.

            for doc, doc_embedding in zip(document_batch, embedding_matrix):
                doc.embedding = doc_embedding
